/**
 * Sistema de an√°lisis multi-pasada para mejorar precisi√≥n
 */

import OpenAI from 'openai';
import { calculateAdvancedMetrics, getMetricsAdjustment, interpretMetrics } from './advancedMetrics';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

interface AnalysisResult {
  probability: number;
  confidenceLevel: 'low' | 'medium' | 'high';
  scores_by_category: {
    markersIA: number;
    markersHuman: number;
  };
  linguistic_footprints: Array<{ phrase: string; reason: string }>;
  model: 'gpt-3.5-turbo' | 'gpt-4o-mini';
}

/**
 * Prompt principal para detecci√≥n de IA (optimizado)
 */
function getMainAnalysisPrompt(text: string): string {
  return `Eres un detector especializado en textos en espa√±ol (Espa√±a y LATAM). Determina si fue generado por IA o escrito por un humano.

PATRONES IA ESPEC√çFICOS (0-25 puntos):
1. Frases clich√©:
   - "cabe destacar que", "es importante mencionar", "en conclusi√≥n"
   - "a continuaci√≥n", "sin lugar a dudas", "en este sentido"
   - "por lo tanto", "en primer lugar", "resulta evidente"
2. Estructura mec√°nica:
   - Introducci√≥n ‚Üí desarrollo ‚Üí conclusi√≥n perfecta
   - Transiciones predecibles: "por otro lado", "finalmente"
   - P√°rrafos de longitud muy uniforme
3. Gram√°tica perfecta:
   - Cero errores tipogr√°ficos o gramaticales
   - Puntuaci√≥n impecable y consistente
   - Uso formal excesivo sin variaci√≥n
4. Genericidad:
   - Ideas abstractas sin ejemplos concretos
   - Vocabulario t√©cnico sin personalidad
   - Falta de opiniones subjetivas

PATRONES HUMANOS ESPEC√çFICOS (0-25 puntos):
1. Imperfecciones naturales:
   - Errores tipogr√°ficos ocasionales
   - Faltas gramaticales menores
   - Cambios de tema abruptos
2. Expresividad:
   - Modismos regionales: "che", "vos", "pibe", "re", "boludo", "t√≠o", "flipar"
   - Opiniones personales sin justificar
   - Emociones expl√≠citas (enojo, alegr√≠a, frustraci√≥n)
3. Estilo informal:
   - Mezcla de registros (formal/informal)
   - Digresiones y par√©ntesis
   - Preguntas ret√≥ricas
4. Variaci√≥n:
   - Longitud de oraciones muy variada
   - Cambios de ritmo narrativo
   - Puntuaci√≥n irregular

EJEMPLOS:

Texto IA (alta probabilidad):
"Es importante mencionar que la inteligencia artificial representa un avance significativo. En este sentido, cabe destacar que sus aplicaciones son diversas. Por lo tanto, resulta evidente que su impacto ser√° considerable."

Texto Humano (baja probabilidad):
"Mira, la IA est√° re copada pero tampoco es que vaya a resolver todo. Hay gente que flashea demasiado con esto. A ver, s√≠, es √∫til... pero bueno, ya vamos a ver qu√© pasa."

TEXTO A ANALIZAR:
"""${text}"""

Responde en formato JSON:
{
  "probability": number,
  "confidenceLevel": "low" | "medium" | "high",
  "scores_by_category": {
    "markersIA": number,
    "markersHuman": number
  },
  "linguistic_footprints": [
    { "phrase": string, "reason": string }
  ]
}

IMPORTANTE: En "linguistic_footprints", SOLO incluye frases que aparecen LITERALMENTE en el texto analizado arriba. NO inventes frases ni parafrasees. Copia EXACTAMENTE las frases sospechosas del texto original. Si no hay frases espec√≠ficas sospechosas, devuelve un array vac√≠o [].`;
}

/**
 * Prompt de validaci√≥n (enfoque diferente)
 */
function getValidationPrompt(text: string): string {
  return `Eres un validador de an√°lisis de texto. Tu trabajo es evaluar si este texto fue escrito por humano o IA usando un enfoque diferente.

ENFOQUE DE VALIDACI√ìN:
Enf√≥cate en lo que la IA NO PUEDE hacer bien:

1. Errores humanos naturales:
   - ¬øHay inconsistencias l√≥gicas menores?
   - ¬øHay repeticiones innecesarias?
   - ¬øCambios de tiempo verbal inesperados?

2. Contexto cultural:
   - ¬øUsa referencias culturales espec√≠ficas?
   - ¬øMenciona experiencias personales concretas?
   - ¬øHay jerga muy espec√≠fica de una regi√≥n?

3. Emocionalidad:
   - ¬øExpresa frustraci√≥n, alegr√≠a, enojo genuino?
   - ¬øUsa exageraciones o hip√©rboles?
   - ¬øHay sarcasmo o iron√≠a?

4. Estilo ca√≥tico:
   - ¬øOraciones incompletas o fragmentadas?
   - ¬øIdeas que no siguen un orden perfecto?
   - ¬øPuntuaci√≥n irregular o creativa?

Si el texto tiene MUCHAS de estas caracter√≠sticas ‚Üí Probable humano (baja probabilidad IA)
Si el texto es perfecto, formal, estructurado ‚Üí Probable IA (alta probabilidad)

TEXTO:
"""${text}"""

Responde en JSON:
{
  "probability": number,
  "confidenceLevel": "low" | "medium" | "high",
  "scores_by_category": {
    "markersIA": number,
    "markersHuman": number
  },
  "linguistic_footprints": [
    { "phrase": string, "reason": string }
  ]
}

IMPORTANTE: En "linguistic_footprints", SOLO incluye frases que aparecen LITERALMENTE en el texto analizado arriba. NO inventes frases ni parafrasees. Copia EXACTAMENTE las frases del texto original. Si no hay frases espec√≠ficas sospechosas, devuelve un array vac√≠o [].`;
}

/**
 * Realiza an√°lisis con GPT-3.5-turbo
 */
async function analyzeWithGPT35(prompt: string): Promise<AnalysisResult> {
  const completion = await openai.chat.completions.create({
    model: 'gpt-3.5-turbo',
    messages: [
      {
        role: 'system',
        content: 'Eres un analizador de textos que responde en formato JSON.',
      },
      {
        role: 'user',
        content: prompt,
      },
    ],
    temperature: 0.3,
    max_tokens: 2048,
    response_format: { type: 'json_object' },
  });

  const result = JSON.parse(completion.choices[0].message.content || '{}');
  return {
    ...result,
    model: 'gpt-3.5-turbo',
  };
}

/**
 * Realiza an√°lisis con GPT-4o-mini (modelo superior)
 */
async function analyzeWithGPT4oMini(prompt: string): Promise<AnalysisResult> {
  const completion = await openai.chat.completions.create({
    model: 'gpt-4o-mini',
    messages: [
      {
        role: 'system',
        content: 'Eres un analizador experto de textos que responde en formato JSON.',
      },
      {
        role: 'user',
        content: prompt,
      },
    ],
    temperature: 0.2,
    max_tokens: 3000,
    response_format: { type: 'json_object' },
  });

  const result = JSON.parse(completion.choices[0].message.content || '{}');
  return {
    ...result,
    model: 'gpt-4o-mini',
  };
}

/**
 * Combina m√∫ltiples an√°lisis con pesos inteligentes (FASE 2 - actualizado para 4 passes)
 */
function combineAnalysisResults(
  analysis1: AnalysisResult,
  analysis2: AnalysisResult,
  analysis3: AnalysisResult,
  analysis4: AnalysisResult | null,
  metricsAdjustment: number
): {
  probability: number;
  confidenceLevel: 'low' | 'medium' | 'high';
  usedModels: string[];
} {
  const results = [analysis1, analysis2, analysis3];
  if (analysis4) results.push(analysis4);

  // Calcular probabilidad promedio con pesos
  let totalWeight = 0;
  let weightedSum = 0;

  results.forEach((result, index) => {
    // FASE 2: Todos son GPT-4o-mini ahora, peso base igual
    const baseWeight = 1.0;
    // Primera an√°lisis tiene ligeramente m√°s peso (prompt principal)
    const indexWeight = index === 0 ? 1.2 : 1.0;
    // Cuarto an√°lisis (desempate) tiene peso extra
    const tiebreakWeight = index === 3 ? 1.3 : 1.0;
    const finalWeight = baseWeight * indexWeight * tiebreakWeight;

    weightedSum += result.probability * finalWeight;
    totalWeight += finalWeight;
  });

  let probability = weightedSum / totalWeight;

  // Aplicar ajuste de m√©tricas
  probability = Math.max(0, Math.min(100, probability + metricsAdjustment));

  // Calcular nivel de confianza basado en dispersi√≥n
  const probabilities = results.map(r => r.probability);
  const mean = probabilities.reduce((a, b) => a + b, 0) / probabilities.length;
  const variance = probabilities.reduce((sum, val) => sum + Math.pow(val - mean, 2), 0) / probabilities.length;
  const stdDev = Math.sqrt(variance);

  let confidenceLevel: 'low' | 'medium' | 'high';
  if (stdDev < 8) {
    confidenceLevel = 'high'; // Los an√°lisis coinciden mucho
  } else if (stdDev < 15) {
    confidenceLevel = 'medium';
  } else {
    confidenceLevel = 'low'; // Los an√°lisis difieren mucho
  }

  const usedModels = results.map(r => r.model);

  return {
    probability: Math.round(probability),
    confidenceLevel,
    usedModels,
  };
}

/**
 * Sistema de an√°lisis mejorado FREE (FASE 2)
 * - Triple validaci√≥n con GPT-4o-mini SIEMPRE (100% de an√°lisis)
 * - 4to pass autom√°tico si divergencia > 25 puntos
 * - M√©tricas avanzadas
 * - Scoring ponderado por importancia de footprints
 */
export async function improvedFreeAnalysis(
  text: string,
  textType: string = 'default',
  isRegisteredUser: boolean = false
): Promise<{
  probability: number;
  confidenceLevel: 'low' | 'medium' | 'high';
  scores_by_category: {
    markersIA: number;
    markersHuman: number;
  };
  linguistic_footprints: Array<{ phrase: string; reason: string }>;
  advancedMetrics: any;
  metricsInsights: string[];
  usedModels: string[];
  analysisDetails: {
    pass1Probability: number;
    pass2Probability: number;
    pass3Probability: number;
    pass4Probability?: number;
    metricsAdjustment: number;
  };
}> {
  // PASO 1: An√°lisis principal con GPT-4o-mini (MEJORADO - antes GPT-3.5)
  const mainPrompt = getMainAnalysisPrompt(text);
  const analysis1 = await analyzeWithGPT4oMini(mainPrompt);

  // PASO 2: Validaci√≥n cruzada con GPT-4o-mini (MEJORADO - antes GPT-3.5)
  const validationPrompt = getValidationPrompt(text);
  const analysis2 = await analyzeWithGPT4oMini(validationPrompt);

  // PASO 3: Tercer an√°lisis SIEMPRE con GPT-4o-mini (MEJORADO - antes condicional)
  const analysis3 = await analyzeWithGPT4oMini(mainPrompt);

  // PASO 4: Calcular m√©tricas avanzadas
  const advancedMetrics = calculateAdvancedMetrics(text);
  const metricsAdjustment = getMetricsAdjustment(advancedMetrics);
  const metricsInsights = interpretMetrics(advancedMetrics);

  // PASO 5: Verificar si necesitamos 4to pass por alta divergencia
  const probabilities = [analysis1.probability, analysis2.probability, analysis3.probability];
  const maxProb = Math.max(...probabilities);
  const minProb = Math.min(...probabilities);
  const divergence = maxProb - minProb;

  let analysis4: AnalysisResult | null = null;

  // NUEVO: 4to pass de desempate si divergencia > 25 puntos
  if (divergence > 25) {
    // Usar prompt de validaci√≥n para tener perspectiva diferente
    analysis4 = await analyzeWithGPT4oMini(validationPrompt);
  }

  // PASO 6: Combinar resultados
  const combined = combineAnalysisResults(analysis1, analysis2, analysis3, analysis4, metricsAdjustment);

  // PASO 7: Combinar scores y footprints (ACTUALIZADO para incluir 4to pass)
  const allResults = [analysis1, analysis2, analysis3];
  if (analysis4) allResults.push(analysis4);

  const avgMarkersIA = Math.round(
    allResults.reduce((sum, r) => sum + r.scores_by_category.markersIA, 0) / allResults.length
  );
  const avgMarkersHuman = Math.round(
    allResults.reduce((sum, r) => sum + r.scores_by_category.markersHuman, 0) / allResults.length
  );

  // FASE 2: Combinar footprints con SCORING PONDERADO por importancia
  interface WeightedFootprint {
    phrase: string;
    reason: string;
    weight: number;
    occurrences: number;
  }

  const footprintMap = new Map<string, WeightedFootprint>();

  allResults.forEach((result, analysisIndex) => {
    result.linguistic_footprints.forEach((fp, fpIndex) => {
      const existing = footprintMap.get(fp.phrase);

      // Calcular peso basado en:
      // 1. Posici√≥n en la lista (primeros son m√°s relevantes): peso 3.0 a 1.0
      const positionWeight = fpIndex === 0 ? 3.0 : fpIndex === 1 ? 2.5 : fpIndex === 2 ? 2.0 : 1.5;

      // 2. N√∫mero de an√°lisis que lo detectaron (consenso): +0.5 por cada aparici√≥n adicional
      const occurrenceBonus = existing ? 0.5 : 0;

      // 3. An√°lisis principal tiene m√°s peso: 1.2x
      const analysisWeight = analysisIndex === 0 ? 1.2 : 1.0;

      const totalWeight = (positionWeight + occurrenceBonus) * analysisWeight;

      if (existing) {
        // Ya existe, incrementar occurrences y actualizar peso si es mayor
        existing.occurrences += 1;
        existing.weight = Math.max(existing.weight, totalWeight);
      } else {
        // Nuevo footprint
        footprintMap.set(fp.phrase, {
          phrase: fp.phrase,
          reason: fp.reason,
          weight: totalWeight,
          occurrences: 1,
        });
      }
    });
  });

  // Convertir a array y ordenar por peso (m√°s peso = m√°s importante)
  const weightedFootprints = Array.from(footprintMap.values()).sort((a, b) => b.weight - a.weight);

  // üö® VALIDACI√ìN CR√çTICA: Filtrar footprints que NO aparecen en el texto original
  // Esto previene alucinaciones donde GPT inventa frases o incluye contenido del prompt
  const validatedFootprints = weightedFootprints.filter(fp => {
    if (!fp.phrase || fp.phrase.trim().length === 0) {
      return false; // Eliminar frases vac√≠as
    }

    // Normalizar para comparaci√≥n: min√∫sculas y sin espacios extra
    const normalizedText = text.toLowerCase().trim();
    const normalizedPhrase = fp.phrase.toLowerCase().trim();

    // Verificar que la frase aparece LITERALMENTE en el texto original
    const existsInText = normalizedText.includes(normalizedPhrase);

    // Log para debugging (solo en desarrollo)
    if (!existsInText && process.env.NODE_ENV === 'development') {
      console.warn(`‚ö†Ô∏è Footprint filtrado (no existe en texto): "${fp.phrase}"`);
    }

    return existsInText;
  });

  // Convertir de vuelta al formato esperado (sin el peso)
  const finalFootprints = validatedFootprints.slice(0, 8).map(wf => ({
    phrase: wf.phrase,
    reason: wf.reason,
  }));

  return {
    probability: combined.probability,
    confidenceLevel: combined.confidenceLevel,
    scores_by_category: {
      markersIA: avgMarkersIA,
      markersHuman: avgMarkersHuman,
    },
    linguistic_footprints: finalFootprints, // Ahora ordenados por importancia ponderada
    advancedMetrics,
    metricsInsights,
    usedModels: combined.usedModels,
    analysisDetails: {
      pass1Probability: analysis1.probability,
      pass2Probability: analysis2.probability,
      pass3Probability: analysis3.probability,
      pass4Probability: analysis4?.probability,
      metricsAdjustment,
    },
  };
}
