import { NextResponse } from 'next/server';
import OpenAI from 'openai';
import { createClient } from '@/lib/supabase/server';
import { checkRateLimit, getRateLimitHeaders } from '@/lib/tracking/checkRateLimit';
import { trackUsage } from '@/lib/tracking/trackUsage';
import { saveToHistory } from '@/lib/history/saveToHistory';

// Initialize OpenAI client
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// Nueva funci√≥n de filtrado de frases sospechosas
function filterPhrases(phrases: Array<{ phrase: string; reason: string }>) {
  const blacklist = ["soluci√≥n", "eficaz", "optimizar"];
  return phrases.filter(p =>
    p.phrase.split(" ").length >= 4 &&
    !blacklist.some(b => p.phrase.toLowerCase().includes(b))
  );
}

// Preprocesamiento avanzado antes del an√°lisis
function enhancePreprocessing(text: string): string {
  // Modismos comunes que suelen ser ignorados por GPT
  const regionalisms = [
    "che", "laburo", "pibe", "re bien", "posta", "chau", "dale", "vale", "t√≠o", "currar", "flipar"
  ];
  regionalisms.forEach(word => {
    text = text.replace(new RegExp(`\\b${word}\\b`, "gi"), `¬´${word}¬ª`);
  });
  // Limpieza de muletillas que inducen error
  text = text.replace(/\b(aqu√≠|eso|este)\b/gi, "");
  return text;
}

// Funci√≥n para calcular la entrop√≠a del texto
function calculateEntropy(text: string): number {
  const tokens = text.split(/\s+/).filter(Boolean);
  const freq: Record<string, number> = {};
  tokens.forEach(token => {
    freq[token] = (freq[token] || 0) + 1;
  });
  const total = tokens.length;
  const probabilities = Object.values(freq).map(f => f / total);
  const entropy = -probabilities.reduce((sum, p) => sum + p * Math.log2(p), 0);
  return parseFloat(entropy.toFixed(2));
}

function getInterpretation(prob: number, type: string, entropyScore?: number) {
  // Interpretaciones basadas en m√©tricas cuantitativas
  let quantitativeNote = "";
  if (entropyScore !== undefined) {
    if (entropyScore < 3.5) {
      quantitativeNote = " El texto es extremadamente repetitivo (entrop√≠a baja), lo que es t√≠pico de IA.";
    } else if (entropyScore > 5.5) {
      quantitativeNote = " El texto muestra alta variabilidad, indicando autor√≠a humana.";
    }
  }

  if (type === "academic") {
    if (prob >= 85) return "Muy probablemente generado por IA. El texto muestra patrones t√≠picos de IA incluso para contenido acad√©mico." + quantitativeNote;
    if (prob >= 60) return "Probablemente IA, pero la estructura formal acad√©mica puede confundir el an√°lisis." + quantitativeNote;
    if (prob >= 40) return "No concluyente. Los textos acad√©micos suelen tener estructura r√≠gida que puede parecer IA." + quantitativeNote;
    if (prob >= 20) return "Probablemente humano, con estilo acad√©mico natural." + quantitativeNote;
    return "Muy probablemente escrito por un humano con estilo acad√©mico formal." + quantitativeNote;
  } else if (type === "informal") {
    if (prob >= 85) return "Muy probablemente generado por IA. El texto es demasiado perfecto para ser conversacional." + quantitativeNote;
    if (prob >= 60) return "Probablemente IA, aunque algunos patrones informales est√°n presentes." + quantitativeNote;
    if (prob >= 40) return "No concluyente. Mezcla de elementos informales y patrones sospechosos." + quantitativeNote;
    if (prob >= 20) return "Probablemente humano, con estilo conversacional natural." + quantitativeNote;
    return "Muy probablemente escrito por un humano con lenguaje informal y espont√°neo." + quantitativeNote;
  } else {
    // Tipo por defecto
    if (prob >= 85) return "Muy probablemente generado por IA." + quantitativeNote;
    if (prob >= 60) return "Probablemente IA, pero podr√≠a ser humano." + quantitativeNote;
    if (prob >= 40) return "No concluyente, posible mezcla o texto reformulado." + quantitativeNote;
    if (prob >= 20) return "Probablemente humano, pero con patrones sospechosos." + quantitativeNote;
    return "Muy probablemente escrito por un humano." + quantitativeNote;
  }
}

// Nueva funci√≥n para ajustar probabilidad seg√∫n tipo de texto
function adjustProbabilityByTextType(
  probability: number,
  textType: string,
  scores: { markersIA: number; markersHuman: number },
  entropyScore: number
): number {
  let adjustedProbability = probability;

  // Ajustes basados en entrop√≠a (independiente del tipo de texto)
  if (entropyScore < 3.5) {
    // Texto extremadamente repetitivo - muy probable IA
    adjustedProbability = Math.max(adjustedProbability, 80);
  } else if (entropyScore < 4.0) {
    // Texto muy repetitivo - probable IA
    adjustedProbability = Math.max(adjustedProbability, 70);
  } else if (entropyScore > 5.5) {
    // Texto muy variado - probable humano
    adjustedProbability = Math.min(adjustedProbability, 35);
  }

  // Ajustes espec√≠ficos por tipo de texto
  if (textType === "academic") {
    // Para textos acad√©micos, ser m√°s permisivo con estructura r√≠gida
    // pero m√°s estricto con frases gen√©ricas
    if (scores.markersIA >= 15 && scores.markersHuman >= 10) {
      // Si tiene muchos marcadores de ambos tipos, probablemente es humano
      adjustedProbability = Math.min(adjustedProbability, 45);
    } else if (scores.markersIA >= 18 && scores.markersHuman <= 8) {
      // Si tiene muchos marcadores IA y pocos humanos, mantener alto
      adjustedProbability = Math.max(adjustedProbability, 70);
    } else if (entropyScore < 4.0) {
      // Texto muy repetitivo
      adjustedProbability = Math.max(adjustedProbability, 70);
    } else {
      // Ajuste general para acad√©micos: reducir falsos positivos
      adjustedProbability = Math.max(0, adjustedProbability - 8);
    }
  } else if (textType === "informal") {
    // Para textos informales, ser m√°s permisivo con modismos y errores
    // pero m√°s estricto con estructura perfecta
    if (scores.markersHuman >= 15 && scores.markersIA <= 12) {
      // Si tiene muchos marcadores humanos y pocos IA, es muy probable humano
      adjustedProbability = Math.min(adjustedProbability, 30);
    } else if (scores.markersIA >= 16 && scores.markersHuman <= 8) {
      // Si tiene muchos marcadores IA y pocos humanos, mantener alto
      adjustedProbability = Math.max(adjustedProbability, 65);
    } else if (entropyScore > 5.0) {
      // Texto muy variado
      adjustedProbability = Math.min(adjustedProbability, 35);
    } else {
      // Ajuste general para informales: reducir falsos negativos
      adjustedProbability = Math.min(100, adjustedProbability + 5);
    }
  }

  return Math.max(0, Math.min(100, adjustedProbability));
}

export async function POST(request: Request) {
  console.log("Usando GPT-3.5 Turbo"); // Debug temporal
  try {
    const { text, textType = "default", anonymousId } = await request.json();

    // Obtener userId si est√° autenticado
    const supabase = await createClient();
    const {
      data: { user },
    } = await supabase.auth.getUser();
    const userId = user?.id || null;

    // üö® RATE LIMITING CHECK
    const rateLimit = await checkRateLimit({
      userId: userId || undefined,
      anonymousId: anonymousId || undefined,
      toolType: 'detector',
    });

    // Si alcanz√≥ el l√≠mite, retornar 429
    if (!rateLimit.allowed) {
      return NextResponse.json(
        {
          error: 'L√≠mite diario alcanzado',
          message:
            rateLimit.userType === 'anonymous'
              ? `Usaste tus ${rateLimit.limit} an√°lisis gratis hoy. Reg√≠strate para obtener ${50} an√°lisis diarios.`
              : `Alcanzaste el l√≠mite de ${rateLimit.limit} an√°lisis diarios. Vuelve ma√±ana o actualiza a Premium.`,
          limit: rateLimit.limit,
          remaining: rateLimit.remaining,
          resetAt: rateLimit.resetAt,
          userType: rateLimit.userType,
        },
        {
          status: 429,
          headers: getRateLimitHeaders(rateLimit),
        }
      );
    }

    // Validate input
    if (!text || typeof text !== 'string') {
      return NextResponse.json(
        { error: 'El texto es requerido' },
        { status: 400 }
      );
    }

    if (text.length > 1200) {
      return NextResponse.json(
        { error: 'El texto no puede exceder los 1200 caracteres' },
        { status: 400 }
      );
    }

    // Nuevo prompt avanzado y preprocesamiento
    const prompt = `Eres un detector especializado en textos en espa√±ol contempor√°neo (Espa√±a y LATAM). Tu tarea es determinar si un texto fue generado por IA o escrito por un humano, usando criterios ling√º√≠sticos avanzados.\n\nEval√∫a lo siguiente (0 a 25 puntos cada uno):\n\n1. **Marcadores de IA**:\n   - Frases gen√©ricas como \"optimizaci√≥n de procesos estrat√©gicos\"\n   - Estructura gramatical r√≠gida o excesivamente limpia\n   - Bajo uso de conectores variados\n   - Falta de errores o ambig√ºedad t√≠pica del lenguaje humano\n\n2. **Marcadores Humanos**:\n   - Uso de modismos o expresiones locales (\"che\", \"re bien\", \"vos\", etc.)\n   - Subjetividad u opiniones personales\n   - Estilo informal o mezcla de registros\n   - Digresiones o estructuras parcialmente ca√≥ticas\n\n**Retorno esperado (en JSON):**\n{\n  \"probability\": number, // 0 a 100\n  \"confidenceLevel\": \"low\" | \"medium\" | \"high\",\n  \"scores_by_category\": {\n    \"markersIA\": number,\n    \"markersHuman\": number\n  },\n  \"linguistic_footprints\": [\n    { \"phrase\": string, \"reason\": string }\n  ]\n}\n\nTexto a analizar:\n\"\"\"${enhancePreprocessing(text)}\"\"\"`;

    // Call OpenAI API to analyze the text
    const completion = await openai.chat.completions.create({
      model: "gpt-3.5-turbo",
      messages: [
        {
          role: "system",
          content: "Eres un analizador de textos que responde en formato JSON."
        },
        {
          role: "user",
          content: prompt
        }
      ],
      temperature: 0.3,
      max_tokens: 2048,
      response_format: { type: "json_object" }
    });

    let analysis;
    try {
      analysis = JSON.parse(completion.choices[0].message.content || '{}');
    } catch (e) {
      return NextResponse.json(
        { error: 'La respuesta de OpenAI no es un JSON v√°lido.' },
        { status: 500 }
      );
    }

    // Validar estructura esperada del nuevo output
    if (
      typeof analysis.probability !== 'number' ||
      !['low', 'medium', 'high'].includes(analysis.confidenceLevel) ||
      typeof analysis.scores_by_category !== 'object' ||
      typeof analysis.scores_by_category.markersIA !== 'number' ||
      typeof analysis.scores_by_category.markersHuman !== 'number' ||
      !Array.isArray(analysis.linguistic_footprints)
    ) {
      return NextResponse.json(
        { error: 'La respuesta de OpenAI no tiene el formato esperado.' },
        { status: 500 }
      );
    }

    // Calcular entrop√≠a
    const entropyScore = calculateEntropy(text);

    // Ajuste de probabilidad seg√∫n tipo de texto (l√≥gica mejorada)
    let adjustedProbability = analysis.probability;

    // --- Validaci√≥n de coherencia para evitar falsos positivos ---
    const { markersIA, markersHuman } = analysis.scores_by_category;
    if (markersHuman >= 15 && markersIA <= 10 && adjustedProbability > 40) {
      adjustedProbability = 40;
    }
    if (markersIA >= 15 && markersHuman <= 10 && adjustedProbability < 60) {
      adjustedProbability = 60;
    }
    // ------------------------------------------------------------

    // Aplicar ajuste inteligente seg√∫n tipo de texto
    adjustedProbability = adjustProbabilityByTextType(
      adjustedProbability,
      textType,
      analysis.scores_by_category,
      entropyScore
    );

    // ‚úÖ TRACK USAGE - Registrar uso exitoso
    await trackUsage({
      userId: userId || undefined,
      anonymousId: anonymousId || undefined,
      toolType: 'detector',
      characterCount: text.length,
      metadata: {
        textType,
        probability: adjustedProbability,
        confidenceLevel: analysis.confidenceLevel,
        entropyScore,
      },
    });

    // üíæ SAVE TO HISTORY - Guardar en historial (solo usuarios autenticados)
    if (userId) {
      await saveToHistory({
        userId,
        toolType: 'detector',
        inputText: text,
        outputText: JSON.stringify({
          probability: adjustedProbability,
          confidenceLevel: analysis.confidenceLevel,
          interpretation: getInterpretation(adjustedProbability, textType, entropyScore),
        }),
        characterCount: text.length,
        metadata: {
          textType,
          probability: adjustedProbability,
          confidenceLevel: analysis.confidenceLevel,
          entropyScore,
          scores_by_category: analysis.scores_by_category,
        },
      });
    }

    // Retornar con headers de rate limit
    return NextResponse.json(
      {
        probability: adjustedProbability,
        confidenceLevel: analysis.confidenceLevel,
        scores_by_category: analysis.scores_by_category,
        linguistic_footprints: analysis.linguistic_footprints,
        entropyScore,
        interpretation: getInterpretation(adjustedProbability, textType, entropyScore),
        rateLimit: {
          remaining: rateLimit.remaining - 1,
          limit: rateLimit.limit,
          resetAt: rateLimit.resetAt,
        },
      },
      {
        headers: getRateLimitHeaders({
          ...rateLimit,
          remaining: rateLimit.remaining - 1,
        }),
      }
    );
  } catch (error) {
    console.error('Error analyzing text:', error);
    return NextResponse.json(
      { error: 'Error al analizar el texto' },
      { status: 500 }
    );
  }
} 